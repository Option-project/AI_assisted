{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Découper le texte en chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text: str, chunk_size: int = 512) -> list:\n",
    "    \"\"\"\n",
    "    Divise un texte en chunks de taille fixe\n",
    "\n",
    "    Input: \n",
    "    -----\n",
    "        Texte brut.\n",
    "    Parameters:\n",
    "    -----------\n",
    "      chunk_size: Nombre maximum de mots par chunk.\n",
    "    Returns: \n",
    "    -------\n",
    "        base de données de chunks \n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    print(f\"Divisé en {len(chunks)} chunks.\")\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divisé en 1 chunks.\n",
      "Premier chunk : L'intelligence artificielle (IA) est un domaine de l'informatique qui vise à créer des systèmes capables d'exécuter des tâches qui nécessitent normalement une intelligence humaine. Parmi ces tâches, on trouve la reconnaissance vocale, la vision par ordinateur, la prise de décision et la traduction de langues. L'IA peut être classée en deux grandes catégories : l'IA faible et l'IA forte. L'IA faible est conçue pour exécuter une tâche spécifique, comme les assistants virtuels (par exemple, Siri ou Alexa). L'IA forte, quant à elle, a pour objectif de reproduire l'intelligence humaine dans son ensemble, y compris les émotions et la créativité. Le traitement du langage naturel (NLP) est une sous-discipline importante de l'IA, permettant aux machines de comprendre et de répondre au langage humain. Grâce à des avancées majeures dans les modèles de langage, comme GPT et BERT, le NLP a considérablement amélioré les performances dans des domaines comme le service client et la traduction automatique. Enfin, l'IA continue d'évoluer à un rythme rapide, avec des applications dans presque tous les secteurs, de la santé à l'éducation, en passant par la finance et les transports.\n"
     ]
    }
   ],
   "source": [
    "document_text = \"\"\"\n",
    "L'intelligence artificielle (IA) est un domaine de l'informatique qui vise à créer des systèmes capables d'exécuter des tâches qui nécessitent normalement une intelligence humaine.\n",
    "Parmi ces tâches, on trouve la reconnaissance vocale, la vision par ordinateur, la prise de décision et la traduction de langues.\n",
    "\n",
    "L'IA peut être classée en deux grandes catégories : l'IA faible et l'IA forte. L'IA faible est conçue pour exécuter une tâche spécifique, comme les assistants virtuels (par exemple, Siri ou Alexa).\n",
    "L'IA forte, quant à elle, a pour objectif de reproduire l'intelligence humaine dans son ensemble, y compris les émotions et la créativité.\n",
    "\n",
    "Le traitement du langage naturel (NLP) est une sous-discipline importante de l'IA, permettant aux machines de comprendre et de répondre au langage humain.\n",
    "Grâce à des avancées majeures dans les modèles de langage, comme GPT et BERT, le NLP a considérablement amélioré les performances dans des domaines comme le service client et la traduction automatique.\n",
    "\n",
    "Enfin, l'IA continue d'évoluer à un rythme rapide, avec des applications dans presque tous les secteurs, de la santé à l'éducation, en passant par la finance et les transports.\n",
    "\"\"\"\n",
    "\n",
    "chunks = split_text_into_chunks(document_text, chunk_size=512)\n",
    "print(f\"Premier chunk : {chunks[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_embeddings(chunks: list, model_name: str = \"paraphrase-multilingual-MiniLM-L12-v2\") -> list:\n",
    "    \"\"\"\n",
    "    Génère les embeddings pour une liste de chunks.\n",
    "    Input :\n",
    "    ------\n",
    "        chunks\n",
    "        model_name\n",
    "    Parameters\n",
    "    ---------\n",
    "        chunks: Liste de chunks de texte.\n",
    "        model_name: Nom du modèle SentenceTransformer.\n",
    "    :return: Liste des embeddings.\n",
    "    \"\"\"\n",
    "    print(f\"Chargement du modèle {model_name}...\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print(\"Génération des embeddings...\")\n",
    "    embeddings = model.encode(chunks, batch_size=16, show_progress_bar=True)\n",
    "    print(f\"Embeddings générés pour {len(embeddings)} chunks.\")\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle paraphrase-multilingual-MiniLM-L12-v2...\n",
      "Génération des embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings générés pour 1 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = generate_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faiss_index(embeddings: np.ndarray, index_file: str):\n",
    "    \"\"\"\n",
    "    Crée et sauvegarde un index FAISS à partir des embeddings\n",
    "\n",
    "    Parameters : \n",
    "    -----------\n",
    "        embeddings: Liste ou tableau numpy des embeddings.\n",
    "        index_file: Chemin pour sauvegarder l'index FAISS.\n",
    "    Output : \n",
    "    ------- \n",
    "        base de données \n",
    "    \"\"\"\n",
    "    dimension = embeddings.shape[1]  # Dimension des vecteurs\n",
    "    print(f\"Création d'un index FAISS avec dimension {dimension}...\")\n",
    "    index = faiss.IndexFlatL2(dimension)  # Index basé sur la distance euclidienne\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, index_file)\n",
    "    print(f\"Index FAISS sauvegardé dans {index_file}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple d'utilisation\n",
    "embeddings_array = np.array(embeddings).astype(\"float32\")\n",
    "create_faiss_index(embeddings_array, \"embeddings/vectors/example_faiss.index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
